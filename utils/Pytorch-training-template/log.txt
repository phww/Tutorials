2021-06-06::20-48-13
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [32, 64, 32, 32]           9,408
       BatchNorm2d-2           [32, 64, 32, 32]             128
              ReLU-3           [32, 64, 32, 32]               0
         MaxPool2d-4           [32, 64, 16, 16]               0
            Conv2d-5           [32, 64, 16, 16]           4,096
       BatchNorm2d-6           [32, 64, 16, 16]             128
              ReLU-7           [32, 64, 16, 16]               0
            Conv2d-8           [32, 64, 16, 16]          36,864
       BatchNorm2d-9           [32, 64, 16, 16]             128
             ReLU-10           [32, 64, 16, 16]               0
           Conv2d-11          [32, 256, 16, 16]          16,384
      BatchNorm2d-12          [32, 256, 16, 16]             512
           Conv2d-13          [32, 256, 16, 16]          16,384
      BatchNorm2d-14          [32, 256, 16, 16]             512
             ReLU-15          [32, 256, 16, 16]               0
       Bottleneck-16          [32, 256, 16, 16]               0
           Conv2d-17           [32, 64, 16, 16]          16,384
      BatchNorm2d-18           [32, 64, 16, 16]             128
             ReLU-19           [32, 64, 16, 16]               0
           Conv2d-20           [32, 64, 16, 16]          36,864
      BatchNorm2d-21           [32, 64, 16, 16]             128
             ReLU-22           [32, 64, 16, 16]               0
           Conv2d-23          [32, 256, 16, 16]          16,384
      BatchNorm2d-24          [32, 256, 16, 16]             512
             ReLU-25          [32, 256, 16, 16]               0
       Bottleneck-26          [32, 256, 16, 16]               0
           Conv2d-27           [32, 64, 16, 16]          16,384
      BatchNorm2d-28           [32, 64, 16, 16]             128
             ReLU-29           [32, 64, 16, 16]               0
           Conv2d-30           [32, 64, 16, 16]          36,864
      BatchNorm2d-31           [32, 64, 16, 16]             128
             ReLU-32           [32, 64, 16, 16]               0
           Conv2d-33          [32, 256, 16, 16]          16,384
      BatchNorm2d-34          [32, 256, 16, 16]             512
             ReLU-35          [32, 256, 16, 16]               0
       Bottleneck-36          [32, 256, 16, 16]               0
           Conv2d-37          [32, 128, 16, 16]          32,768
      BatchNorm2d-38          [32, 128, 16, 16]             256
             ReLU-39          [32, 128, 16, 16]               0
           Conv2d-40            [32, 128, 8, 8]         147,456
      BatchNorm2d-41            [32, 128, 8, 8]             256
             ReLU-42            [32, 128, 8, 8]               0
           Conv2d-43            [32, 512, 8, 8]          65,536
      BatchNorm2d-44            [32, 512, 8, 8]           1,024
           Conv2d-45            [32, 512, 8, 8]         131,072
      BatchNorm2d-46            [32, 512, 8, 8]           1,024
             ReLU-47            [32, 512, 8, 8]               0
       Bottleneck-48            [32, 512, 8, 8]               0
           Conv2d-49            [32, 128, 8, 8]          65,536
      BatchNorm2d-50            [32, 128, 8, 8]             256
             ReLU-51            [32, 128, 8, 8]               0
           Conv2d-52            [32, 128, 8, 8]         147,456
      BatchNorm2d-53            [32, 128, 8, 8]             256
             ReLU-54            [32, 128, 8, 8]               0
           Conv2d-55            [32, 512, 8, 8]          65,536
      BatchNorm2d-56            [32, 512, 8, 8]           1,024
             ReLU-57            [32, 512, 8, 8]               0
       Bottleneck-58            [32, 512, 8, 8]               0
           Conv2d-59            [32, 128, 8, 8]          65,536
      BatchNorm2d-60            [32, 128, 8, 8]             256
             ReLU-61            [32, 128, 8, 8]               0
           Conv2d-62            [32, 128, 8, 8]         147,456
      BatchNorm2d-63            [32, 128, 8, 8]             256
             ReLU-64            [32, 128, 8, 8]               0
           Conv2d-65            [32, 512, 8, 8]          65,536
      BatchNorm2d-66            [32, 512, 8, 8]           1,024
             ReLU-67            [32, 512, 8, 8]               0
       Bottleneck-68            [32, 512, 8, 8]               0
           Conv2d-69            [32, 128, 8, 8]          65,536
      BatchNorm2d-70            [32, 128, 8, 8]             256
             ReLU-71            [32, 128, 8, 8]               0
           Conv2d-72            [32, 128, 8, 8]         147,456
      BatchNorm2d-73            [32, 128, 8, 8]             256
             ReLU-74            [32, 128, 8, 8]               0
           Conv2d-75            [32, 512, 8, 8]          65,536
      BatchNorm2d-76            [32, 512, 8, 8]           1,024
             ReLU-77            [32, 512, 8, 8]               0
       Bottleneck-78            [32, 512, 8, 8]               0
           Conv2d-79            [32, 256, 8, 8]         131,072
      BatchNorm2d-80            [32, 256, 8, 8]             512
             ReLU-81            [32, 256, 8, 8]               0
           Conv2d-82            [32, 256, 4, 4]         589,824
      BatchNorm2d-83            [32, 256, 4, 4]             512
             ReLU-84            [32, 256, 4, 4]               0
           Conv2d-85           [32, 1024, 4, 4]         262,144
      BatchNorm2d-86           [32, 1024, 4, 4]           2,048
           Conv2d-87           [32, 1024, 4, 4]         524,288
      BatchNorm2d-88           [32, 1024, 4, 4]           2,048
             ReLU-89           [32, 1024, 4, 4]               0
       Bottleneck-90           [32, 1024, 4, 4]               0
           Conv2d-91            [32, 256, 4, 4]         262,144
      BatchNorm2d-92            [32, 256, 4, 4]             512
             ReLU-93            [32, 256, 4, 4]               0
           Conv2d-94            [32, 256, 4, 4]         589,824
      BatchNorm2d-95            [32, 256, 4, 4]             512
             ReLU-96            [32, 256, 4, 4]               0
           Conv2d-97           [32, 1024, 4, 4]         262,144
      BatchNorm2d-98           [32, 1024, 4, 4]           2,048
             ReLU-99           [32, 1024, 4, 4]               0
      Bottleneck-100           [32, 1024, 4, 4]               0
          Conv2d-101            [32, 256, 4, 4]         262,144
     BatchNorm2d-102            [32, 256, 4, 4]             512
            ReLU-103            [32, 256, 4, 4]               0
          Conv2d-104            [32, 256, 4, 4]         589,824
     BatchNorm2d-105            [32, 256, 4, 4]             512
            ReLU-106            [32, 256, 4, 4]               0
          Conv2d-107           [32, 1024, 4, 4]         262,144
     BatchNorm2d-108           [32, 1024, 4, 4]           2,048
            ReLU-109           [32, 1024, 4, 4]               0
      Bottleneck-110           [32, 1024, 4, 4]               0
          Conv2d-111            [32, 256, 4, 4]         262,144
     BatchNorm2d-112            [32, 256, 4, 4]             512
            ReLU-113            [32, 256, 4, 4]               0
          Conv2d-114            [32, 256, 4, 4]         589,824
     BatchNorm2d-115            [32, 256, 4, 4]             512
            ReLU-116            [32, 256, 4, 4]               0
          Conv2d-117           [32, 1024, 4, 4]         262,144
     BatchNorm2d-118           [32, 1024, 4, 4]           2,048
            ReLU-119           [32, 1024, 4, 4]               0
      Bottleneck-120           [32, 1024, 4, 4]               0
          Conv2d-121            [32, 256, 4, 4]         262,144
     BatchNorm2d-122            [32, 256, 4, 4]             512
            ReLU-123            [32, 256, 4, 4]               0
          Conv2d-124            [32, 256, 4, 4]         589,824
     BatchNorm2d-125            [32, 256, 4, 4]             512
            ReLU-126            [32, 256, 4, 4]               0
          Conv2d-127           [32, 1024, 4, 4]         262,144
     BatchNorm2d-128           [32, 1024, 4, 4]           2,048
            ReLU-129           [32, 1024, 4, 4]               0
      Bottleneck-130           [32, 1024, 4, 4]               0
          Conv2d-131            [32, 256, 4, 4]         262,144
     BatchNorm2d-132            [32, 256, 4, 4]             512
            ReLU-133            [32, 256, 4, 4]               0
          Conv2d-134            [32, 256, 4, 4]         589,824
     BatchNorm2d-135            [32, 256, 4, 4]             512
            ReLU-136            [32, 256, 4, 4]               0
          Conv2d-137           [32, 1024, 4, 4]         262,144
     BatchNorm2d-138           [32, 1024, 4, 4]           2,048
            ReLU-139           [32, 1024, 4, 4]               0
      Bottleneck-140           [32, 1024, 4, 4]               0
          Conv2d-141            [32, 256, 4, 4]         262,144
     BatchNorm2d-142            [32, 256, 4, 4]             512
            ReLU-143            [32, 256, 4, 4]               0
          Conv2d-144            [32, 256, 4, 4]         589,824
     BatchNorm2d-145            [32, 256, 4, 4]             512
            ReLU-146            [32, 256, 4, 4]               0
          Conv2d-147           [32, 1024, 4, 4]         262,144
     BatchNorm2d-148           [32, 1024, 4, 4]           2,048
            ReLU-149           [32, 1024, 4, 4]               0
      Bottleneck-150           [32, 1024, 4, 4]               0
          Conv2d-151            [32, 256, 4, 4]         262,144
     BatchNorm2d-152            [32, 256, 4, 4]             512
            ReLU-153            [32, 256, 4, 4]               0
          Conv2d-154            [32, 256, 4, 4]         589,824
     BatchNorm2d-155            [32, 256, 4, 4]             512
            ReLU-156            [32, 256, 4, 4]               0
          Conv2d-157           [32, 1024, 4, 4]         262,144
     BatchNorm2d-158           [32, 1024, 4, 4]           2,048
            ReLU-159           [32, 1024, 4, 4]               0
      Bottleneck-160           [32, 1024, 4, 4]               0
          Conv2d-161            [32, 256, 4, 4]         262,144
     BatchNorm2d-162            [32, 256, 4, 4]             512
            ReLU-163            [32, 256, 4, 4]               0
          Conv2d-164            [32, 256, 4, 4]         589,824
     BatchNorm2d-165            [32, 256, 4, 4]             512
            ReLU-166            [32, 256, 4, 4]               0
          Conv2d-167           [32, 1024, 4, 4]         262,144
     BatchNorm2d-168           [32, 1024, 4, 4]           2,048
            ReLU-169           [32, 1024, 4, 4]               0
      Bottleneck-170           [32, 1024, 4, 4]               0
          Conv2d-171            [32, 256, 4, 4]         262,144
     BatchNorm2d-172            [32, 256, 4, 4]             512
            ReLU-173            [32, 256, 4, 4]               0
          Conv2d-174            [32, 256, 4, 4]         589,824
     BatchNorm2d-175            [32, 256, 4, 4]             512
            ReLU-176            [32, 256, 4, 4]               0
          Conv2d-177           [32, 1024, 4, 4]         262,144
     BatchNorm2d-178           [32, 1024, 4, 4]           2,048
            ReLU-179           [32, 1024, 4, 4]               0
      Bottleneck-180           [32, 1024, 4, 4]               0
          Conv2d-181            [32, 256, 4, 4]         262,144
     BatchNorm2d-182            [32, 256, 4, 4]             512
            ReLU-183            [32, 256, 4, 4]               0
          Conv2d-184            [32, 256, 4, 4]         589,824
     BatchNorm2d-185            [32, 256, 4, 4]             512
            ReLU-186            [32, 256, 4, 4]               0
          Conv2d-187           [32, 1024, 4, 4]         262,144
     BatchNorm2d-188           [32, 1024, 4, 4]           2,048
            ReLU-189           [32, 1024, 4, 4]               0
      Bottleneck-190           [32, 1024, 4, 4]               0
          Conv2d-191            [32, 256, 4, 4]         262,144
     BatchNorm2d-192            [32, 256, 4, 4]             512
            ReLU-193            [32, 256, 4, 4]               0
          Conv2d-194            [32, 256, 4, 4]         589,824
     BatchNorm2d-195            [32, 256, 4, 4]             512
            ReLU-196            [32, 256, 4, 4]               0
          Conv2d-197           [32, 1024, 4, 4]         262,144
     BatchNorm2d-198           [32, 1024, 4, 4]           2,048
            ReLU-199           [32, 1024, 4, 4]               0
      Bottleneck-200           [32, 1024, 4, 4]               0
          Conv2d-201            [32, 256, 4, 4]         262,144
     BatchNorm2d-202            [32, 256, 4, 4]             512
            ReLU-203            [32, 256, 4, 4]               0
          Conv2d-204            [32, 256, 4, 4]         589,824
     BatchNorm2d-205            [32, 256, 4, 4]             512
            ReLU-206            [32, 256, 4, 4]               0
          Conv2d-207           [32, 1024, 4, 4]         262,144
     BatchNorm2d-208           [32, 1024, 4, 4]           2,048
            ReLU-209           [32, 1024, 4, 4]               0
      Bottleneck-210           [32, 1024, 4, 4]               0
          Conv2d-211            [32, 256, 4, 4]         262,144
     BatchNorm2d-212            [32, 256, 4, 4]             512
            ReLU-213            [32, 256, 4, 4]               0
          Conv2d-214            [32, 256, 4, 4]         589,824
     BatchNorm2d-215            [32, 256, 4, 4]             512
            ReLU-216            [32, 256, 4, 4]               0
          Conv2d-217           [32, 1024, 4, 4]         262,144
     BatchNorm2d-218           [32, 1024, 4, 4]           2,048
            ReLU-219           [32, 1024, 4, 4]               0
      Bottleneck-220           [32, 1024, 4, 4]               0
          Conv2d-221            [32, 256, 4, 4]         262,144
     BatchNorm2d-222            [32, 256, 4, 4]             512
            ReLU-223            [32, 256, 4, 4]               0
          Conv2d-224            [32, 256, 4, 4]         589,824
     BatchNorm2d-225            [32, 256, 4, 4]             512
            ReLU-226            [32, 256, 4, 4]               0
          Conv2d-227           [32, 1024, 4, 4]         262,144
     BatchNorm2d-228           [32, 1024, 4, 4]           2,048
            ReLU-229           [32, 1024, 4, 4]               0
      Bottleneck-230           [32, 1024, 4, 4]               0
          Conv2d-231            [32, 256, 4, 4]         262,144
     BatchNorm2d-232            [32, 256, 4, 4]             512
            ReLU-233            [32, 256, 4, 4]               0
          Conv2d-234            [32, 256, 4, 4]         589,824
     BatchNorm2d-235            [32, 256, 4, 4]             512
            ReLU-236            [32, 256, 4, 4]               0
          Conv2d-237           [32, 1024, 4, 4]         262,144
     BatchNorm2d-238           [32, 1024, 4, 4]           2,048
            ReLU-239           [32, 1024, 4, 4]               0
      Bottleneck-240           [32, 1024, 4, 4]               0
          Conv2d-241            [32, 256, 4, 4]         262,144
     BatchNorm2d-242            [32, 256, 4, 4]             512
            ReLU-243            [32, 256, 4, 4]               0
          Conv2d-244            [32, 256, 4, 4]         589,824
     BatchNorm2d-245            [32, 256, 4, 4]             512
            ReLU-246            [32, 256, 4, 4]               0
          Conv2d-247           [32, 1024, 4, 4]         262,144
     BatchNorm2d-248           [32, 1024, 4, 4]           2,048
            ReLU-249           [32, 1024, 4, 4]               0
      Bottleneck-250           [32, 1024, 4, 4]               0
          Conv2d-251            [32, 256, 4, 4]         262,144
     BatchNorm2d-252            [32, 256, 4, 4]             512
            ReLU-253            [32, 256, 4, 4]               0
          Conv2d-254            [32, 256, 4, 4]         589,824
     BatchNorm2d-255            [32, 256, 4, 4]             512
            ReLU-256            [32, 256, 4, 4]               0
          Conv2d-257           [32, 1024, 4, 4]         262,144
     BatchNorm2d-258           [32, 1024, 4, 4]           2,048
            ReLU-259           [32, 1024, 4, 4]               0
      Bottleneck-260           [32, 1024, 4, 4]               0
          Conv2d-261            [32, 256, 4, 4]         262,144
     BatchNorm2d-262            [32, 256, 4, 4]             512
            ReLU-263            [32, 256, 4, 4]               0
          Conv2d-264            [32, 256, 4, 4]         589,824
     BatchNorm2d-265            [32, 256, 4, 4]             512
            ReLU-266            [32, 256, 4, 4]               0
          Conv2d-267           [32, 1024, 4, 4]         262,144
     BatchNorm2d-268           [32, 1024, 4, 4]           2,048
            ReLU-269           [32, 1024, 4, 4]               0
      Bottleneck-270           [32, 1024, 4, 4]               0
          Conv2d-271            [32, 256, 4, 4]         262,144
     BatchNorm2d-272            [32, 256, 4, 4]             512
            ReLU-273            [32, 256, 4, 4]               0
          Conv2d-274            [32, 256, 4, 4]         589,824
     BatchNorm2d-275            [32, 256, 4, 4]             512
            ReLU-276            [32, 256, 4, 4]               0
          Conv2d-277           [32, 1024, 4, 4]         262,144
     BatchNorm2d-278           [32, 1024, 4, 4]           2,048
            ReLU-279           [32, 1024, 4, 4]               0
      Bottleneck-280           [32, 1024, 4, 4]               0
          Conv2d-281            [32, 256, 4, 4]         262,144
     BatchNorm2d-282            [32, 256, 4, 4]             512
            ReLU-283            [32, 256, 4, 4]               0
          Conv2d-284            [32, 256, 4, 4]         589,824
     BatchNorm2d-285            [32, 256, 4, 4]             512
            ReLU-286            [32, 256, 4, 4]               0
          Conv2d-287           [32, 1024, 4, 4]         262,144
     BatchNorm2d-288           [32, 1024, 4, 4]           2,048
            ReLU-289           [32, 1024, 4, 4]               0
      Bottleneck-290           [32, 1024, 4, 4]               0
          Conv2d-291            [32, 256, 4, 4]         262,144
     BatchNorm2d-292            [32, 256, 4, 4]             512
            ReLU-293            [32, 256, 4, 4]               0
          Conv2d-294            [32, 256, 4, 4]         589,824
     BatchNorm2d-295            [32, 256, 4, 4]             512
            ReLU-296            [32, 256, 4, 4]               0
          Conv2d-297           [32, 1024, 4, 4]         262,144
     BatchNorm2d-298           [32, 1024, 4, 4]           2,048
            ReLU-299           [32, 1024, 4, 4]               0
      Bottleneck-300           [32, 1024, 4, 4]               0
          Conv2d-301            [32, 256, 4, 4]         262,144
     BatchNorm2d-302            [32, 256, 4, 4]             512
            ReLU-303            [32, 256, 4, 4]               0
          Conv2d-304            [32, 256, 4, 4]         589,824
     BatchNorm2d-305            [32, 256, 4, 4]             512
            ReLU-306            [32, 256, 4, 4]               0
          Conv2d-307           [32, 1024, 4, 4]         262,144
     BatchNorm2d-308           [32, 1024, 4, 4]           2,048
            ReLU-309           [32, 1024, 4, 4]               0
      Bottleneck-310           [32, 1024, 4, 4]               0
          Conv2d-311            [32, 512, 4, 4]         524,288
     BatchNorm2d-312            [32, 512, 4, 4]           1,024
            ReLU-313            [32, 512, 4, 4]               0
          Conv2d-314            [32, 512, 2, 2]       2,359,296
     BatchNorm2d-315            [32, 512, 2, 2]           1,024
            ReLU-316            [32, 512, 2, 2]               0
          Conv2d-317           [32, 2048, 2, 2]       1,048,576
     BatchNorm2d-318           [32, 2048, 2, 2]           4,096
          Conv2d-319           [32, 2048, 2, 2]       2,097,152
     BatchNorm2d-320           [32, 2048, 2, 2]           4,096
            ReLU-321           [32, 2048, 2, 2]               0
      Bottleneck-322           [32, 2048, 2, 2]               0
          Conv2d-323            [32, 512, 2, 2]       1,048,576
     BatchNorm2d-324            [32, 512, 2, 2]           1,024
            ReLU-325            [32, 512, 2, 2]               0
          Conv2d-326            [32, 512, 2, 2]       2,359,296
     BatchNorm2d-327            [32, 512, 2, 2]           1,024
            ReLU-328            [32, 512, 2, 2]               0
          Conv2d-329           [32, 2048, 2, 2]       1,048,576
     BatchNorm2d-330           [32, 2048, 2, 2]           4,096
            ReLU-331           [32, 2048, 2, 2]               0
      Bottleneck-332           [32, 2048, 2, 2]               0
          Conv2d-333            [32, 512, 2, 2]       1,048,576
     BatchNorm2d-334            [32, 512, 2, 2]           1,024
            ReLU-335            [32, 512, 2, 2]               0
          Conv2d-336            [32, 512, 2, 2]       2,359,296
     BatchNorm2d-337            [32, 512, 2, 2]           1,024
            ReLU-338            [32, 512, 2, 2]               0
          Conv2d-339           [32, 2048, 2, 2]       1,048,576
     BatchNorm2d-340           [32, 2048, 2, 2]           4,096
            ReLU-341           [32, 2048, 2, 2]               0
      Bottleneck-342           [32, 2048, 2, 2]               0
AdaptiveAvgPool2d-343           [32, 2048, 1, 1]               0
          Linear-344                 [32, 1000]       2,049,000
================================================================
Total params: 44,549,160
Trainable params: 44,549,160
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.50
Forward/backward pass size (MB): 1123.24
Params size (MB): 169.94
Estimated Total Size (MB): 1294.69
----------------------------------------------------------------
None
*************** epoch:1 ***************
loss: 7.27594	cur:[0]\[50000]
loss: 1.25407	cur:[10000]\[50000]
loss: 1.06950	cur:[20000]\[50000]
loss: 1.01799	cur:[30000]\[50000]
loss: 0.98632	cur:[40000]\[50000]
loss: 0.97978	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.96071	cur:[10000]\[10000]
epoch:1	acc:0.25000
*************** epoch:2 ***************
loss: 0.93291	cur:[10000]\[50000]
loss: 0.91560	cur:[20000]\[50000]
loss: 0.90276	cur:[30000]\[50000]
loss: 0.89256	cur:[40000]\[50000]
loss: 0.88123	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.86611	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:2	acc:0.47000
*************** epoch:3 ***************
loss: 0.86597	cur:[10000]\[50000]
loss: 0.85397	cur:[20000]\[50000]
loss: 0.83812	cur:[30000]\[50000]
loss: 0.83305	cur:[40000]\[50000]
loss: 0.82765	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.81449	cur:[10000]\[10000]
epoch:3	acc:0.37000
*************** epoch:4 ***************
loss: 0.81867	cur:[10000]\[50000]
loss: 0.81075	cur:[20000]\[50000]
loss: 0.80069	cur:[30000]\[50000]
loss: 0.78904	cur:[40000]\[50000]
loss: 0.78651	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.78284	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:4	acc:0.49000
*************** epoch:5 ***************
loss: 0.77027	cur:[10000]\[50000]
loss: 0.77203	cur:[20000]\[50000]
loss: 0.79256	cur:[30000]\[50000]
loss: 0.77332	cur:[40000]\[50000]
loss: 0.74867	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.77799	cur:[10000]\[10000]
save model at ./check_point/best.pth
save model at ./check_point/epoch5.pth
epoch:5	acc:0.51000
*************** epoch:6 ***************
loss: 0.74903	cur:[10000]\[50000]
loss: 0.76273	cur:[20000]\[50000]
loss: 0.75431	cur:[30000]\[50000]
loss: 0.74138	cur:[40000]\[50000]
loss: 0.74881	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.74090	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:6	acc:0.51000
*************** epoch:7 ***************
loss: 0.71559	cur:[10000]\[50000]
loss: 0.74057	cur:[20000]\[50000]
loss: 0.72695	cur:[30000]\[50000]
loss: 0.86915	cur:[40000]\[50000]
loss: 0.81112	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.79789	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:7	acc:0.57000
*************** epoch:8 ***************
loss: 0.76489	cur:[10000]\[50000]
loss: 0.76166	cur:[20000]\[50000]
loss: 0.75307	cur:[30000]\[50000]
loss: 0.74552	cur:[40000]\[50000]
loss: 0.84413	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.99576	cur:[10000]\[10000]
epoch:8	acc:0.30000
*************** epoch:9 ***************
loss: 0.86003	cur:[10000]\[50000]
loss: 0.80316	cur:[20000]\[50000]
loss: 0.76717	cur:[30000]\[50000]
loss: 0.76202	cur:[40000]\[50000]
loss: 0.77046	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.84900	cur:[10000]\[10000]
epoch:9	acc:0.46000
*************** epoch:10 ***************
loss: 0.73914	cur:[10000]\[50000]
loss: 0.71973	cur:[20000]\[50000]
loss: 0.71304	cur:[30000]\[50000]
loss: 0.74322	cur:[40000]\[50000]
loss: 0.71221	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.72456	cur:[10000]\[10000]
save model at ./check_point/epoch10.pth
epoch:10	acc:0.45000
*************** epoch:11 ***************
loss: 0.68609	cur:[10000]\[50000]
loss: 0.69510	cur:[20000]\[50000]
loss: 0.67934	cur:[30000]\[50000]
loss: 0.66791	cur:[40000]\[50000]
loss: 0.66191	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.68737	cur:[10000]\[10000]
epoch:11	acc:0.43000
Epoch    11: reducing learning rate of group 0 to 3.0000e-05.
*************** epoch:12 ***************
loss: 0.63212	cur:[10000]\[50000]
loss: 0.61435	cur:[20000]\[50000]
loss: 0.61194	cur:[30000]\[50000]
loss: 0.60424	cur:[40000]\[50000]
loss: 0.61180	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.60944	cur:[10000]\[10000]
epoch:12	acc:0.55000
*************** epoch:13 ***************
loss: 0.58768	cur:[10000]\[50000]
loss: 0.59986	cur:[20000]\[50000]
loss: 0.60145	cur:[30000]\[50000]
loss: 0.59659	cur:[40000]\[50000]
loss: 0.60820	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.60733	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:13	acc:0.57000
*************** epoch:14 ***************
loss: 0.58773	cur:[10000]\[50000]
loss: 0.59525	cur:[20000]\[50000]
loss: 0.59489	cur:[30000]\[50000]
loss: 0.58337	cur:[40000]\[50000]
loss: 0.58856	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.59789	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:14	acc:0.60000
*************** epoch:15 ***************
loss: 0.58517	cur:[10000]\[50000]
loss: 0.57389	cur:[20000]\[50000]
loss: 0.57734	cur:[30000]\[50000]
loss: 0.57434	cur:[40000]\[50000]
loss: 0.58203	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.59366	cur:[10000]\[10000]
save model at ./check_point/best.pth
save model at ./check_point/epoch15.pth
epoch:15	acc:0.62000
*************** epoch:16 ***************
loss: 0.57340	cur:[10000]\[50000]
loss: 0.57476	cur:[20000]\[50000]
loss: 0.57737	cur:[30000]\[50000]
loss: 0.56763	cur:[40000]\[50000]
loss: 0.55921	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.58523	cur:[10000]\[10000]
epoch:16	acc:0.60000
*************** epoch:17 ***************
loss: 0.56077	cur:[10000]\[50000]
loss: 0.56554	cur:[20000]\[50000]
loss: 0.56022	cur:[30000]\[50000]
loss: 0.57469	cur:[40000]\[50000]
loss: 0.55102	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.58583	cur:[10000]\[10000]
epoch:17	acc:0.56000
*************** epoch:18 ***************
loss: 0.54337	cur:[10000]\[50000]
loss: 0.55554	cur:[20000]\[50000]
loss: 0.55133	cur:[30000]\[50000]
loss: 0.55483	cur:[40000]\[50000]
loss: 0.55437	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.58196	cur:[10000]\[10000]
save model at ./check_point/best.pth
epoch:18	acc:0.64000
*************** epoch:19 ***************
loss: 0.53913	cur:[10000]\[50000]
loss: 0.55002	cur:[20000]\[50000]
loss: 0.55123	cur:[30000]\[50000]
loss: 0.54416	cur:[40000]\[50000]
loss: 0.53639	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.56776	cur:[10000]\[10000]
epoch:19	acc:0.62000
*************** epoch:20 ***************
loss: 0.53026	cur:[10000]\[50000]
loss: 0.53806	cur:[20000]\[50000]
loss: 0.53660	cur:[30000]\[50000]
loss: 0.54467	cur:[40000]\[50000]
loss: 0.53373	cur:[50000]\[50000]
--------------- Evaluation ---------------
loss: 0.56210	cur:[10000]\[10000]
save model at ./check_point/epoch20.pth
epoch:20	acc:0.60000
DONE! best acc:0.64
Final_lr:2.9999999999999997e-05
Total Time:1348.3892004489899
